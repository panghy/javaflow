# JavaFlow: Software Requirements Document

## Introduction

**JavaFlow** is a Java-based actor concurrency framework designed to support highly concurrent, asynchronous programming with **deterministic execution** for testing. It reimagines the core ideas of a proven C++ actor framework in idiomatic Java, leveraging JDK 21+ features (notably JDK's Continuation API) instead of any custom compiler or preprocessor. The goal is to combine the simplicity of writing sequential code with the performance of event-driven systems, all within pure Java and minimal third-party libraries. JavaFlow empowers developers to write asynchronous *actors* (lightweight tasks) that communicate via **futures** and **promises**, run on a single-threaded cooperative **event loop**, and can be executed in a special *simulation mode* that reproduces complex distributed scenarios with **deterministic results**.

**Key Objectives:**

* **Actor Model & Futures:** Provide a lightweight *actor* abstraction and a robust **Future/Promise** mechanism for inter-task communication. Writing an actor should feel like writing a normal sequential function using `await`-like operations, without explicit thread management.
* **Cooperative Scheduling:** Use a single-threaded **event loop** to schedule all actors in a **cooperative** manner. Avoid true parallel threads for core logic, ensuring that concurrency is achieved via interleaving tasks rather than multi-threading (which aids determinism).
* **Prioritized Execution:** Assign **priorities** to tasks so that time-critical actors run before lower-priority work. The scheduler must always run the highest-priority ready task next, preventing starvation and honoring task importance.
* **Non-blocking I/O Integration:** All I/O (network, disk, timers, etc.) will be integrated via asynchronous operations that yield futures. No actor will ever block a real OS thread on I/O; instead, I/O completions feed into the event loop as events, maintaining single-threadedness and enabling a *virtual clock* for simulation.
* **Deterministic Simulation:** Support a **simulation mode** where the entire system (multiple actors, network messages, disk events) can run in one thread with a controlled scheduler and clock. This mode allows testing with reproducible results, including **fault injection** (randomized failures) to harden the system.
* **Error Handling & Cancellation:** Integrate exceptions and cancellation deeply into the model. If an asynchronous operation fails, it should throw an exception at the await point (allowing try/catch around `await`). If an actor's result is no longer needed, the framework should **automatically cancel** that actor and any of its dependent subtasks.
* **Logging & Debugging:** Provide rich **debugging and logging infrastructure** tailored for asynchronous actors. This includes structured event logs (with timestamps, actor identifiers, etc.), tools to trace actor call stacks at runtime, and the ability to replay or step through event sequences deterministically.
* **Idiomatic Java Implementation:** Implement all the above using pure Java (JDK 21 or later) features with minimal external dependencies. Leverage JDK's Continuation API for lightweight actor implementation rather than building a custom coroutine system from scratch. JavaFlow should feel natural to Java developers and work with standard tools (profilers, debuggers, etc.) out-of-the-box.

This document details the requirements and design of JavaFlow. It covers the core programming model (actors, futures, streams), the execution and scheduling model, integration with I/O and timers, the deterministic simulation capabilities, error propagation and cancellation semantics, and the debugging/logging facilities. Example Java APIs and pseudocode are included to illustrate how developers will use JavaFlow to write asynchronous actor-based code.

## Core Design Principles and Architecture

JavaFlow's design centers on an **actor-based programming model** built atop a single-threaded scheduler. Key architectural principles include the actor/future abstraction, message-passing via promises, and deterministic task scheduling. This section outlines these core concepts and how they will appear in the JavaFlow API.

* **Actors as Lightweight Tasks:** An *actor* in JavaFlow represents an independent logical task or coroutine that runs concurrently with others. Internally, each actor uses the JDK's Continuation API to maintain its execution state. Actors do not share mutable state by default; they communicate by exchanging messages (values or signals) asynchronously. An actor function typically returns a `FlowFuture<T>` (JavaFlow's future type) representing a result that will be delivered later. Developers write actor code as straightforward sequential logic that can **suspend** at await points without blocking the whole program. Many actors can be in progress at once, but thanks to the single-threaded execution model, at most one will be actively running at any given moment (concurrency without parallelism).

* **Futures and Promises:** JavaFlow's primary concurrency primitives are **futures** and **promises**. A `FlowFuture<T>` is a placeholder for a result of type `T` that may not yet be available. A `FlowPromise<T>` is the completable handle for that future – it can be fulfilled with a value (or an error) exactly once. This decouples producers from consumers: an actor can return a future immediately, and some other actor (or an I/O event) will later set the corresponding promise. Actors can *wait* on futures to get results, which causes the actor to pause until the future is resolved. All actor functions in JavaFlow will return `FlowFuture` instead of returning values directly; this enforces asynchronous, non-blocking behavior. For example, an actor might create a `FlowPromise<ByteBuffer>` and pass it to a disk I/O component; when the disk read completes, that component fulfills the promise with data, which in turn makes the waiting actor's future ready with the data.

* **Message Passing via Futures:** By using futures/promises, JavaFlow enables an **event-driven message-passing** style. One actor can send information to another by simply setting a promise that the other is awaiting. This is effectively a thread-safe single-use channel. The important aspect is location transparency: the sender and receiver might be on different components or even different simulated nodes, but the code for waiting and sending is identical. For instance, an actor can call another actor on a remote service by sending a request (filling a promise in that service's incoming queue) and then waiting on a future for the response. JavaFlow should allow this pattern seamlessly – if remote messaging is built on top of JavaFlow, the future will be resolved when the network reply arrives, but from the actor's perspective it's just waiting on a local future. This principle (present in the original design) ensures the same actor logic can handle local or distributed cases uniformly. **In summary, actors don't call each other directly; they orchestrate by creating and consuming futures.**

* **Streams for Continuous Messages:** In addition to single-value futures, JavaFlow supports **streaming channels** for sequences of values. The API includes a `FlowStream<T>` (with complementary `FlowPublisher<T>` or `FlowPromiseStream<T>`) to represent a stream of messages that one actor produces and another consumes. This acts like an asynchronous queue. For example, a server actor could expose a `FlowStream<Request>` representing incoming client requests; multiple client actors can push requests into it via a `FlowPublisher<Request>`, and the server actor pulls requests one-by-one from the stream. The consumer actor uses an operation like `Flow.awaitNext(stream)` (or an iterator-style API) to wait for the **next item** on the stream. If the stream is empty, the actor will suspend until a new message arrives, then resume with that message. Streams are essential for modeling continuous event sources or actor mailboxes in a convenient way. JavaFlow ensures that stream consumption is also deterministic and that if multiple streams or events are awaited, the selection of which event to handle next is well-defined.

* **Waiting on Multiple Events (Select/Choose):** A powerful pattern in concurrent programming is waiting for *one of many* events to occur and handling whichever happens first. JavaFlow will provide a construct to wait on **multiple futures or stream-next events simultaneously**, akin to a `select` or **choose** operation. In the original model, a `choose { when(F1) {...} or when(F2) {...} }` syntax allowed an actor to be suspended on both F1 and F2 and react to whichever becomes ready first. In JavaFlow, we can achieve a similar outcome by offering a static API like `Flow.select(future1, future2, ...)` that returns a descriptor of which future completed first, or by allowing a lambda-based builder for choose blocks. The key requirement is **deterministic tie-breaking**: if two or more of the awaited events are ready at the same time, the one with the highest priority or the one listed first should be chosen predictably. This determinism ensures that the outcome doesn't depend on race conditions. For example, if an actor is waiting for either a new request or a timeout to occur, and both become ready, the framework might always favor the request first (or whichever was registered first), making behavior reproducible. JavaFlow's API should make it easy to express these "wait for any of these" scenarios. A possible design is:

  ```java
  // Pseudo-code example of waiting for multiple events:
  FlowFuture<Request> nextA = streamA.next();   // future for next item from streamA
  FlowFuture<Request> nextB = streamB.next();   // future for next item from streamB
  FlowSelector<Request> selector = FlowSelector.create()
      .when(nextA, req -> { handleRequestA(req); })
      .when(nextB, req -> { handleRequestB(req); });
  selector.select(); // waits until either nextA or nextB is ready, then runs the corresponding handler
  ```

  In this example, `FlowSelector` is a conceptual helper: it registers two futures and associated actions, and its `select()` call will block the actor until one future resolves, then execute the matching action. Internally, this could be implemented by completing a promise or using `CompletableFuture.anyOf`, but with added deterministic ordering. This is just one illustrative approach – the exact API can be refined – but the requirement is that JavaFlow must support **waiting on multiple futures** in one step, with a clear, deterministic resolution order. This enables patterns like concurrently fetching data from two sources and using whichever responds first, or handling multiple types of incoming events in a single actor loop.

* **Actor-Local State:** JavaFlow ensures actor-local state continuity by using the JDK's Continuation API to store state. This simplifies actor programming compared to some other actor frameworks. However, it is still important in documentation to caution developers about state management for actors. JavaFlow's actors behave similarly to threads in that local variables are preserved across awaits, providing a straightforward mental model: **what happens within one actor's function stays within that actor's stack and scope, across waits**.

With these core concepts – actors & futures, promises for message passing, streams, multi-wait selects, and preserved state – JavaFlow establishes its programming model. Next, we detail how these actors are executed and scheduled on a single thread to achieve concurrency without parallelism, as well as how I/O and timing are incorporated.

## Execution Model and Task Scheduling

JavaFlow employs a **single-threaded, cooperative scheduling** model to run all actor tasks. This means that, although there may be many actors alive and ready to do work, only one is ever running on the CPU at a time, and context switches occur only at well-defined yield points (such as awaiting a future or explicitly yielding). This design is crucial for simplifying reasoning about concurrency and enabling deterministic simulations. Below we outline the execution model requirements, including the event loop, task prioritization, yielding behavior, and how the JDK's Continuation API is utilized under the hood.

* **Single-Threaded Event Loop:** At the heart of JavaFlow is an **event loop** that continually selects a ready task (actor) and runs it for a slice of execution, then repeats. All actors run on the same OS thread (the *JavaFlow main thread*) by default. This avoids the nondeterminism of preemptive multithreading – no two actor contexts truly run in parallel, so interleaving of operations is controlled by JavaFlow. The event loop is implemented by using a dedicated Java thread with a custom continuation-based scheduler. This ensures that actors are executed one-by-one in a deterministic order on a single OS thread. **No global locks** are needed for actor coordination because they don't run concurrently; shared data is protected by design since only one actor touches the CPU at a time.

* **Task Prioritization:** Every actor (or discrete task posted to the event loop) in JavaFlow has an associated **priority level** (an enum). Lower numeric values indicate higher priority. The scheduler always picks the highest-priority ready task to run next. This allows critical operations (e.g. heartbeats, coordination messages) to preempt less important work (like background cleanup). JavaFlow defines a set of priority levels for common categories (critical, default, low, idle) and allows tasks to specify a priority when scheduled. If not specified, a default priority is used. The system also prevents starvation of low-priority tasks through **priority aging** – gradually raising the priority of tasks that have been waiting longer. This ensures fairness over time. The scheduler's priority queue is the core data structure: tasks ready to run are kept in a structure sorted by priority (and FIFO order within the same priority).

* **Cooperative Multitasking and Yields:** Actors yield control in JavaFlow by awaiting on futures or by explicitly yielding. Since the scheduling is cooperative, an actor will continue to run until it either: (a) awaits a `FlowFuture` that isn't ready (at which point it suspends and the scheduler will switch to another task), or (b) explicitly calls a yield operation, or (c) completes. JavaFlow provides a utility future `Flow.yield()` (of type `FlowFuture<Void>`) that an actor can await to voluntarily give up the CPU. For example, if an actor is performing a long computation or loop, inserting `Flow.await(Flow.yield())` periodically will suspend the actor and let others run, resuming it in the next loop cycle. This prevents any single actor from monopolizing the event loop. JavaFlow also logs a warning if an actor runs for too long without an await (similar to a "SlowTask" log). In summary, **await** calls (on I/O, on timers, or on yields) are the *only* points where context switches occur. There is no preemptive timeslicing by the OS; thus, developers must ensure their actor code reaches an await regularly. The benefit is that scheduling is entirely deterministic and under the framework's control – no random preemption mid-calculation.

* **Event Loop Mechanics:** The main event loop intermixes **actor execution** and **I/O event polling** in each iteration. In pseudocode, the loop might look like this:

  ```java
  while (!shutdown) {
      // 1. Run one ready actor task (highest priority first)
      ActorTask task = readyQueue.poll();  // get next task to run
      if (task != null) {
          task.resume();  // resume the actor's execution for a time-slice
      }

      // 2. Process one pending I/O or timer event, if any
      Event event = ioEventQueue.poll();  // get next completed I/O or timer event
      if (event != null) {
          event.completePromise();  // fulfill the promise associated with that I/O
      }

      // 3. If no actors are ready, wait for the next I/O event (blocking the loop briefly)
      if (readyQueue.isEmpty()) {
          waitForNextIOEvent();  // e.g., block on a selector or sleep until next timer
      }
  }
  ```

* **Deterministic Task Processing with Pump Method:** For testing and deterministic execution, JavaFlow provides a **pump method** that allows manual processing of ready tasks without relying on the carrier thread. This method is especially useful for simulation and testing scenarios where fine-grained control over task execution is needed. The pump method takes a snapshot of all currently ready tasks and processes them in priority order, returning the number of tasks processed. This ensures deterministic ordering, manual control, batch processing, and proper cancellation integration.

* **Integration with JDK Continuation API:** JavaFlow creates each actor using the JDK's Continuation API to allow suspending and resuming execution. This approach is simpler than using virtual threads, as it gives full control over scheduling and continuations. When an actor calls `Flow.await(someFuture)`, the Continuation API suspends that actor and the scheduler can run another task from its queue. When the awaited future completes, the actor is placed back on the ready queue. This effectively implements an event loop using the Continuation API's scheduling.

* **Handling Slow Tasks:** JavaFlow includes mechanisms to detect and handle actors that overrun their time. Since there's no timer preemption, an actor that forgets to yield could stall the system. If an iteration of the event loop takes longer than a certain threshold (e.g. 100ms) without returning to the loop, JavaFlow can log a **Slow Task** warning. This warning includes which actor or operation was running and possibly a snapshot of its stack trace. This helps developers pinpoint performance issues.

* **Task Lifetime and Implicit Cancellation:** JavaFlow implements **automatic cancellation propagation**. If a `FlowFuture` is explicitly cancelled, the system stops the corresponding actor task from continuing, to avoid doing useless work. JavaFlow provides an API like `FlowFuture.cancel()` that signals cancellation, and ensures that actors can handle cancellation at await points. When a cancellation is detected, JavaFlow unwinds the actor's stack (using a `FlowCancelledException` that the actor might catch or, if uncaught, will simply terminate the actor). The scheduler removes the cancelled task from the ready queue. Furthermore, any futures that the cancelled actor was going to set are marked as cancelled or error, propagating the cancellation downstream. This cascading cancellation feature is critical for building timeouts and bounding resource use. For instance, if a client request times out, the entire chain of actors handling that request is torn down promptly. In summary, **the scheduler and future system cooperate to remove cancelled tasks and propagate cancellation events**, all without requiring a lot of manual code in the actors themselves.

In essence, JavaFlow's execution model combines a **deterministic event loop** with priority scheduling and cooperative multitasking. By using one thread of execution and explicit yield points, it guarantees that given the same sequence of events, tasks will interleave in a predictable way every time. This lays the foundation for the deterministic simulation mode. Next, we discuss how external I/O and timers are folded into this single-threaded model.

## Asynchronous I/O and Timers Integration

For a concurrency framework to be practical, it must interface with real-world I/O – network sockets, file reads/writes, timers, etc. JavaFlow adopts a fully asynchronous, non-blocking approach to all I/O, so that even though it has a single-threaded core, I/O operations do not stall the event loop. Instead, all I/O operations return futures that complete when the I/O is done. This section describes how JavaFlow integrates with Java's I/O capabilities and manages timers, both in real mode and simulation mode.

* **Non-Blocking I/O via Futures:** In JavaFlow, any network or disk operation is initiated asynchronously and represented by a `FlowFuture`. For example, reading from a file is done with an API like `FlowFile.read(offset, length)` returning `FlowFuture<ByteBuffer>`. An actor can `Flow.await()` that future to get the data once the read completes. Under the hood, there are a few ways to implement this in Java:

    * Using Java NIO (Non-blocking I/O) with selectors: e.g., for sockets, use a single `Selector` that monitors multiple channels. When a channel is readable or writable, the selector wakes up, and JavaFlow then completes the corresponding promise and resumes the waiting actor.
    * Using Java's asynchronous channels: e.g., `AsynchronousSocketChannel` or `AsynchronousFileChannel`. Using a thread pool could violate single-thread determinism if results come back concurrently. A safe approach is to perform actual blocking I/O on separate helper threads (or use OS async APIs), but funnel the completion back into the **JavaFlow event loop thread**.

  The requirement is that **JavaFlow's main loop remains responsive and never blocks on I/O**. Instead, it uses either OS-level async I/O or background threads. When data is ready, a **promise fulfillment event** is queued. By controlling how many such events are processed per loop iteration (for example, one at a time), JavaFlow maintains deterministic ordering of I/O events. Two network packets arriving at the same time will be handled one after the other in a defined order, not in parallel. This determinism extends to file I/O completions as well. To implement this, JavaFlow maintains an internal **I/O event queue**. The sources feeding this queue could be:

    * A dedicated I/O monitor thread that waits on a Java `Selector` (for sockets) and posts events.
    * Callback handlers for `AsynchronousFileChannel` that put completion events into the queue.
    * Timer events from a scheduler (detailed below).

  Ultimately, in real-world mode, JavaFlow uses a combination of Java NIO and scheduled tasks. The design hides this from the actor developer: to them, it appears that calling `FlowFile.read()` gives a future they can wait on, which completes when the read is done (or errors if the file operation failed), etc. **All I/O APIs in JavaFlow return a `FlowFuture` rather than blocking**. This uniform approach means the same `Flow.await()` mechanism handles both internal waits (between actors) and external waits (on device I/O).

* **Timers and Delays:** Timers are essential for timeouts, periodic tasks, and simulation of delays. JavaFlow includes a utility like `Flow.delay(double seconds)` returning `FlowFuture<Void>` which becomes ready after the specified duration. In production mode, implementing `delay` could use Java's `ScheduledExecutorService` or `Timer` to schedule a task that completes a promise after the given time. However, to keep consistency, timer events are enqueued to be picked up by the main event loop. JavaFlow maintains a **min-heap of timers** (ordered by next expiration time) within the main thread. Each iteration of the loop checks the head of this heap to see if the earliest timer is due to fire. If so, it completes that timer's promise and pops it. Additionally, when the event loop would otherwise go to sleep waiting for I/O, it should calculate how long to sleep based on the next timer deadline. This way, timers integrate cleanly with the event loop without needing separate threads per timer. The `Flow.delay` future in simulation mode uses a virtual clock, but in real mode it uses the system clock. JavaFlow provides a way to get the current time (`Flow.now()`) which gives either real wall-clock time or simulated time depending on mode.

* **Ensuring Deterministic Order of Events:** A core requirement for JavaFlow is that the order in which events (I/O completions, timers, actor resumes) are processed is deterministic or at least controllable. By running a single thread and pulling at most one external event per loop iteration, we impose an order. If multiple events (say two sockets readable) are ready at once, the one our code polls first will be handled first. We can define that ordering (for instance, always handle at most one network event then one timer, etc.) to avoid race conditions. JavaFlow ensures deterministic event handling, especially for the simulation mode, where I/O is simulated.

* **Example – Network Receive:** Suppose an actor is waiting on data from a connection via `Flow.await(connection.receive())`, where `connection.receive()` returns a `FlowFuture<ByteBuffer>`. Under the hood, JavaFlow registers that connection with I/O event monitoring. The actor's continuation is suspended. When the connection actually has data, an I/O event is enqueued. The event carries the data (or indicates error/closure) and links to the promise inside that `FlowFuture`. In the event loop, when we `processNextIOEvent`, we fulfill the promise with the read data. This automatically marks the `FlowFuture` as ready. After processing the I/O event, the waiting actor is placed back on the ready queue. In the next iteration of the loop, the scheduler will see that actor now has a result and is ready to run; it will then resume the actor code after the `await` call, now with the data available. All of this happens on one thread in a controlled sequence.

* **Disk I/O and Thread Pools:** For file operations, JavaFlow uses `AsynchronousFileChannel`. The threads in this pool perform blocking reads/writes and then schedule completions on the main loop. The requirement is to **serialize those completions on the main thread**. This means even if multiple file operations finish in parallel, we queue each result and the event loop will handle them one by one. This maintains determinism in file operation ordering.

* **Minimal Dependencies:** JavaFlow primarily relies on JDK classes for I/O (like `java.nio.channels.Selector`, `SocketChannel`, `ServerSocketChannel`, `AsynchronousFileChannel`, etc.) rather than pulling in large external libraries. This satisfies the requirement of minimal third-party dependencies.

In summary, JavaFlow wraps all networking and disk operations in futures that integrate into the single-threaded event loop. Timers are treated similarly as scheduled events. The system ensures that only one such event is processed at a time, preserving the deterministic, cooperative nature of execution. This design not only makes concurrency safe and predictable, but also sets the stage for the **Deterministic Simulation Mode**, where these real-world interfaces are replaced with simulated ones.

## Implementation Status

As of the current version, JavaFlow's implementation status is as follows:

- **Core Abstractions**: Fully implemented. `FlowFuture`, `FlowPromise`, `FlowStream`, etc.
- **Scheduling System**: Fully implemented with priority-based scheduling and priority aging.
- **File I/O**: Fully implemented with both real (`RealFlowFile`) and simulated (`SimulatedFlowFile`) implementations.
- **Network Layer**: Fully implemented with `FlowConnection` and `FlowTransport` interfaces, plus both real and simulated implementations.
- **RPC Framework**: Design completed, but implementation pending. The core network transport is ready, but the higher-level RPC functionality is still in the design phase.

The next phases of development will focus on completing the RPC framework implementation and enhancing the simulation capabilities to provide a full deterministic testing environment.

## Conclusion

JavaFlow is a comprehensive reimplementation of an actor-framework geared toward high concurrency and rigorous correctness, delivered in pure Java. By marrying the **actor model** (with futures, promises, and streams) to Java's **Continuation API**, it allows developers to write asynchronous code that looks and feels synchronous, without needing any custom language extensions. The single-threaded, prioritized **scheduler** ensures consistent ordering and eliminates data races in the core logic, while the **deterministic simulation mode** provides an unparalleled testing ground for distributed algorithms, complete with controllable fault injection and reproducibility.

This software requirements document has detailed the key features JavaFlow provides: from the core API primitives like `FlowFuture`, `FlowPromise`, and `FlowStream`, to the inner workings of the event loop and integration with I/O, to advanced aspects like error propagation, automatic cancellation, and debugging tools. Each requirement is grounded in making the system both **powerful** (able to handle real-world demands of I/O and parallelism) and **predictable** (so that developers can trust the system's behavior and easily debug it).

JavaFlow adheres to using Java 21+ standard features, minimizing external dependencies. The Continuation API handles cooperative multitasking, and the entire framework remains friendly to standard Java tooling and practices. Logging and monitoring are built-in to ensure that even a complex web of actors can be understood and monitored in production.

Ultimately, JavaFlow brings to the Java ecosystem the proven benefits of the Flow-like approach – highly concurrent performance, simpler async code, and rock-solid reliability through simulation testing – all while staying idiomatic to Java and leveraging its latest advancements. By following the requirements and design outlined here, we create a tool that can serve as the foundation for building robust distributed systems and services in Java, with confidence in their behavior and correctness.